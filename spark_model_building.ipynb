{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3\n",
    "\n",
    "# Spark and Spark Streaming: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer, StopWordsRemover\n",
    "from pyspark.ml.feature import ChiSqSelector, NGram, VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('C:/Users/user/Desktop/data/part-*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(files[0])\n",
    "for fp in files[1:]:\n",
    "    df_temp = spark.read.json(fp)\n",
    "    df = df.union(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df_pd = df.toPandas()\n",
    "df_pd['review_score']=pd.to_numeric(df_pd['review_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1de5ec37a58>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pd['review_score'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of review scores \n",
      "5 = 64.0%\n",
      "4 = 29.67%\n",
      "3 = 2.67%\n",
      "2 = 2.0%\n",
      "1 = 1.67%\n"
     ]
    }
   ],
   "source": [
    "five = round(len(df_pd[df_pd.review_score==5])*100/len(df_pd), 2)\n",
    "four = round(len(df_pd[df_pd.review_score==4])*100/len(df_pd), 2)\n",
    "three = round(len(df_pd[df_pd.review_score==3])*100/len(df_pd), 2)\n",
    "two = round(len(df_pd[df_pd.review_score==2])*100/len(df_pd), 2)\n",
    "one = round(len(df_pd[df_pd.review_score==1])*100/len(df_pd), 2)\n",
    "\n",
    "print(\"Percentage of review scores \")\n",
    "print(\"5 = \"+ str(five)+ \"%\")\n",
    "print(\"4 = \"+ str(four)+ \"%\")\n",
    "print(\"3 = \"+ str(three)+ \"%\")\n",
    "print(\"2 = \"+ str(two)+ \"%\")\n",
    "print(\"1 = \"+ str(one)+ \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2], seed=123)\n",
    "train = train.select('review_text', 'review_score')\n",
    "test = test.select('review_text', 'review_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have downloaded the data and split them into a train and a test set, we are ready to implement several routines to analyse the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We specify three pipelines consisting of different feature building and selection techniques.\n",
    "\n",
    "\n",
    "#### Pipeline 1\n",
    "One gram + hashingTF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"tf\")\n",
    "idf1 = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=2)\n",
    "indexer = StringIndexer(inputCol=\"review_score\", outputCol=\"label\").fit(df)\n",
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedSCORE\", labels=indexer.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline 2\n",
    "One gram + Count Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"words\")\n",
    "#remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "cv2 = CountVectorizer(vocabSize=2**16, inputCol=\"filtered\", outputCol='cv')\n",
    "idf2 = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=2)\n",
    "#indexer = StringIndexer(inputCol=\"review_score\", outputCol=\"label\").fit(df)\n",
    "#converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedSCORE\", labels=indexer.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline 3\n",
    "bi gram + Count Vectorizer  + Chi-Squared feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer3 = [Tokenizer(inputCol=\"review_text\", outputCol=\"words\")]\n",
    "remover3 = [StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")]\n",
    "bigrams = [NGram(n=i, inputCol=\"filtered\", outputCol=\"{0}_grams\".format(i)) for i in range(1, 3)]\n",
    "cv3 = [CountVectorizer(vocabSize=2**14,inputCol=\"{0}_grams\".format(i), outputCol=\"{0}_tf\".format(i)) for i in range(1, 3)]\n",
    "idf3 = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=2) for i in range(1, 3)]\n",
    "assembler = [VectorAssembler(inputCols=[\"{0}_tfidf\".format(i) for i in range(1, 3)], outputCol=\"rawFeatures\")]\n",
    "selector = [ChiSqSelector(numTopFeatures=2**10, featuresCol='rawFeatures', outputCol=\"features\")]\n",
    "indexer3 = [StringIndexer(inputCol=\"review_score\", outputCol=\"label\").fit(df)]\n",
    "converter3 = [IndexToString(inputCol=\"prediction\", outputCol=\"predictedSCORE\", labels=indexer.labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We apply a multinomial Logistic Regression on top of the three different pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "\n",
    "# pipeline 1\n",
    "lr1_pipe = Pipeline(stages=[tokenizer, remover, hashingTF, idf1, indexer, lr, converter])\n",
    "lr1_fit = lr1_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline 2\n",
    "lr2_pipe = Pipeline(stages=[tokenizer, remover, cv2, idf2, indexer, lr, converter])\n",
    "lr2_fit = lr2_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = [LogisticRegression(maxIter=10, regParam=0.01)]\n",
    "# pipeline 3\n",
    "lr3_pipe = Pipeline(stages= tokenizer3 + remover3 + bigrams + cv3 + idf3  + assembler + indexer3 + selector + lr3 + converter3)\n",
    "lr3_fit = lr3_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are displayed the performances of the Logistic Regressions in terms of accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression-Pipeline 1 Test set accuracy = 0.8\n",
      "Logistic Regression-Pipeline 2 Test set accuracy = 0.8\n",
      "Logistic Regression-Pipeline 3 Test set accuracy = 0.8363636363636363\n"
     ]
    }
   ],
   "source": [
    "lr1_res = lr1_fit.transform(test)\n",
    "lr1_pred = lr1_res.select(\"prediction\", \"label\")\n",
    "\n",
    "lr2_res = lr2_fit.transform(test)\n",
    "lr2_pred = lr2_res.select(\"prediction\", \"label\")\n",
    "\n",
    "lr3_res = lr3_fit.transform(test)\n",
    "lr3_pred = lr3_res.select(\"prediction\", \"label\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Logistic Regression-Pipeline 1 Test set accuracy = \" + str(evaluator.evaluate(lr1_pred)))\n",
    "print(\"Logistic Regression-Pipeline 2 Test set accuracy = \" + str(evaluator.evaluate(lr2_pred)))\n",
    "print(\"Logistic Regression-Pipeline 3 Test set accuracy = \" + str(evaluator.evaluate(lr3_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "We apply a Naive Bayes classifier on top of the three different pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# pipeline 1\n",
    "nb1_pipe = Pipeline(stages=[tokenizer, remover, hashingTF, idf1, indexer, nb, converter])\n",
    "nb1_fit = nb1_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline 2\n",
    "nb2_pipe = Pipeline(stages=[tokenizer, remover, cv2, idf2, indexer, nb, converter])\n",
    "nb2_fit = nb2_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb3 = [NaiveBayes(smoothing=1.0, modelType=\"multinomial\")]\n",
    "\n",
    "# pipeline 3\n",
    "nb3_pipe = Pipeline(stages= tokenizer3 + remover3 + bigrams + cv3 + idf3  + assembler + indexer3 + selector + nb3 + converter3)\n",
    "nb3_fit = nb3_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are displayed the performances of the Naive Bayes Classifier in terms of accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes-Pipeline 1 Test set accuracy = 0.8181818181818182\n",
      "Naive Bayes-Pipeline 2 Test set accuracy = 0.8\n",
      "Naive Bayes-Pipeline 3 Test set accuracy = 0.7090909090909091\n"
     ]
    }
   ],
   "source": [
    "nb1_res = nb1_fit.transform(test)\n",
    "nb1_pred = nb1_res.select(\"prediction\", \"label\")\n",
    "\n",
    "nb2_res = nb2_fit.transform(test)\n",
    "nb2_pred = nb2_res.select(\"prediction\", \"label\")\n",
    "\n",
    "nb3_res = nb3_fit.transform(test)\n",
    "nb3_pred = nb3_res.select(\"prediction\", \"label\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Naive Bayes-Pipeline 1 Test set accuracy = \" + str(evaluator.evaluate(nb1_pred)))\n",
    "print(\"Naive Bayes-Pipeline 2 Test set accuracy = \" + str(evaluator.evaluate(nb2_pred)))\n",
    "print(\"Naive Bayes-Pipeline 3 Test set accuracy = \" + str(evaluator.evaluate(nb3_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "We build a Random Forest classifier on top of the three different pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=25)\n",
    "\n",
    "# pipeline 1\n",
    "rf1_pipe = Pipeline(stages=[tokenizer, remover, hashingTF, idf1, indexer, rf, converter])\n",
    "rf1_fit = rf1_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline 2\n",
    "rf2_pipe = Pipeline(stages=[tokenizer, remover, cv2, idf2, indexer, rf, converter])\n",
    "rf2_fit = rf2_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = [RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=25)]\n",
    "\n",
    "# pipeline 3\n",
    "rf3_pipe = Pipeline(stages= tokenizer3 + remover3 + bigrams + cv3 + idf3  + assembler + indexer3 + selector + nb3 + converter3)\n",
    "rf3_fit = rf3_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are displayed the performances of the Random Forests in terms of accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest-Pipeline 1 Test set accuracy = 0.6363636363636364\n",
      "Random Forest-Pipeline 2 Test set accuracy = 0.7272727272727273\n",
      "Random Forest-Pipeline 3 Test set accuracy = 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "rf1_res = rf1_fit.transform(test)\n",
    "rf1_pred = rf1_res.select(\"prediction\", \"label\")\n",
    "\n",
    "rf2_res = rf2_fit.transform(test)\n",
    "rf2_pred = rf2_res.select(\"prediction\", \"label\")\n",
    "\n",
    "rf3_res = rf3_fit.transform(test)\n",
    "rf3_pred = rf3_res.select(\"prediction\", \"label\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Random Forest-Pipeline 1 Test set accuracy = \" + str(evaluator.evaluate(rf1_pred)))\n",
    "print(\"Random Forest-Pipeline 2 Test set accuracy = \" + str(evaluator.evaluate(rf2_pred)))\n",
    "print(\"Random Forest-Pipeline 3 Test set accuracy = \" + str(evaluator.evaluate(rf3_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Best Model\n",
    "\n",
    "Now we are ready to save the chosen model in order to employ it on the streaming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_fit.save('C:/Users/user/Desktop/spark/lr_FinalModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
